{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPfWfI/qSlevDdup/8tsim+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Whoami666/HSE/blob/main/pubmed_project/Data_analysis_pubmed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import gdown\n",
        "from http.client import IncompleteRead\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "yV0UwUUTVlhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "fD3RdlZVfTGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AsUlPQ7kWBGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1-09Noy8YBdbnToOukDbl2QESmUG0Hav-\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/pubmed2006.xlsx\")"
      ],
      "metadata": {
        "id": "E9SqKXy8W050"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "id": "HlcnIxbJXyCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#проверяем на дубли\n",
        "duplicate_rows = df[df.duplicated()]\n",
        "duplicate_rows"
      ],
      "metadata": {
        "id": "WDq8hfYNYA3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['true_citations_cnt'] = df.Citations.apply(lambda x: len(x))\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df['true_citations_cnt'], bins=40, color='skyblue', edgecolor='black')\n",
        "plt.xlabel('Цитирования')\n",
        "plt.ylabel('Статьи')\n",
        "plt.title('Citation count')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(df['PmcRefCount'],  bins=40, color='salmon', edgecolor='black')\n",
        "plt.xlabel('Цитирования')\n",
        "plt.ylabel('Статьи')\n",
        "plt.title('PmcRefCount')\n",
        "\n",
        "# Adjust layout to prevent overlapping\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "JgDfMeV0YJlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_best = df[df['true_citations_cnt'] > 10]\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df_best['true_citations_cnt'], bins=40, color='skyblue', edgecolor='black')\n",
        "plt.xlabel('Цитирования')\n",
        "plt.ylabel('Статьи')\n",
        "plt.title('Citation count > 10')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(df_best['PmcRefCount'],  bins=40, color='salmon', edgecolor='black')\n",
        "plt.xlabel('Цитирования')\n",
        "plt.ylabel('Статьи')\n",
        "plt.title('PmcRefCount')\n",
        "\n",
        "# Adjust layout to prevent overlapping\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SJ4fRSZKd9nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Самые популярные слова**"
      ],
      "metadata": {
        "id": "wGWAVgZPgD28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "0qmfLnJxgFyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "liQT1TInjpXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_text = ' '.join(df['Abstract'].apply(str))\n",
        "clean_text = re.sub(r'[^a-zA-Z\\s]', '', combined_text).lower()\n",
        "words = word_tokenize(clean_text)\n",
        "stop_words = set(stopwords.words('english') + ['may', 'also', 'results', 'study', 'role', 'studies'])\n",
        "words = [word for word in words if word not in stop_words]\n",
        "word_counts = Counter(words)\n",
        "\n",
        "most_common_words = word_counts.most_common(20)\n",
        "most_common_words"
      ],
      "metadata": {
        "id": "sKYQozVafx2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specific_litter = ['show', 'may', 'also', 'results', 'study', 'role', 'studies', 'nan', 'play', 'important', 'study',\n",
        "                   'characterized', 'using', 'showed', 'significantly',  'including', 'disease', 'compared', 'criteria',\n",
        "                   'group', 'groups', 'found', 'several', 'although',  'therefore',  'performed',  'could',\n",
        "                   'present', 'results', 'suggest', 'patients', 'alzheimers', 'alzheimer', 'ad']"
      ],
      "metadata": {
        "id": "dUgVTGmJhYOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    textcleaner = set(re.sub(r'[^a-zA-Z\\s]', '', combined_text).lower().split())\n",
        "    return set(text.split())\n",
        "  #.apply(lambda x: ' '.join(set(re.sub(r'[^a-zA-Z\\s]', '', x).lower().split()))))"
      ],
      "metadata": {
        "id": "2aatsFUAmbiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_common_phrases_in_column(n=2, num_phrases=5):\n",
        "    combined_text = ' '.join(df['Abstract'].apply(str))\n",
        "\n",
        "    clean_text = re.sub(r'[^a-zA-Z\\s]', '', combined_text).lower()\n",
        "    words = word_tokenize(clean_text)\n",
        "    stop_words = set(stopwords.words('english') + specific_litter)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    phrases = list(ngrams(words, n))\n",
        "    phrase_counts = Counter(phrases)\n",
        "    for phrase, count in phrase_counts.items():\n",
        "      phrase_counts[phrase] = (count, round((count / len(df_best)), 3))\n",
        "\n",
        "    most_common_phrases = phrase_counts.most_common(num_phrases)\n",
        "    return most_common_phrases\n",
        "\n",
        "def get_most_common_phrases_in_column_best(n=2, num_phrases=5):\n",
        "    combined_text = ' '.join(df_best['Abstract'].apply(str)) #.apply(lambda x: ' '.join(set(re.sub(r'[^a-zA-Z\\s]', '', x).lower().split()))))\n",
        "\n",
        "    clean_text = re.sub(r'[^a-zA-Z\\s]', '', combined_text).lower()\n",
        "    words = word_tokenize(clean_text)\n",
        "    stop_words = set(stopwords.words('english') + specific_litter)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    phrases = list(ngrams(words, n))\n",
        "    phrase_counts = Counter(phrases)\n",
        "    for phrase, count in phrase_counts.items():\n",
        "      phrase_counts[phrase] = (count, round((count / len(df_best)), 3))\n",
        "\n",
        "\n",
        "    most_common_phrases = phrase_counts.most_common(num_phrases)\n",
        "    return most_common_phrases"
      ],
      "metadata": {
        "id": "kpDU3FSqeZKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_common_bigrams_abstract = get_most_common_phrases_in_column(n=2, num_phrases=20)\n",
        "\n",
        "bigrams = [bigram[0] for bigram in most_common_bigrams_abstract]\n",
        "counts = []\n",
        "for bigram in most_common_bigrams_abstract:\n",
        "  counts += [bigram[1][0]]\n",
        "\n",
        "plt.barh(range(len(bigrams)), counts, color='skyblue')\n",
        "plt.yticks(range(len(bigrams)), [' '.join(bigram) for bigram in bigrams])\n",
        "plt.xlabel('Occurrence Count')\n",
        "plt.ylabel('Bigrams')\n",
        "plt.title('Occurrence Count of Bigrams')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yl5mRrn0fiTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_common_trigrams_abstract = get_most_common_phrases_in_column(n=3, num_phrases=20)\n",
        "\n",
        "bigrams = [bigram[0] for bigram in most_common_trigrams_abstract]\n",
        "counts = []\n",
        "for bigram in most_common_trigrams_abstract:\n",
        "  counts += [bigram[1][0]]\n",
        "\n",
        "plt.barh(range(len(bigrams)), counts, color='skyblue')\n",
        "plt.yticks(range(len(bigrams)), [' '.join(bigram) for bigram in bigrams])\n",
        "plt.xlabel('Occurrence Count')\n",
        "plt.ylabel('Trigrams')\n",
        "plt.title('Occurrence Count of Trigrams')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "axBCzoRciAJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_common_fourgrams_abstract = get_most_common_phrases_in_column(n=4, num_phrases=10)\n",
        "\n",
        "bigrams = [bigram[0] for bigram in most_common_fourgrams_abstract]\n",
        "counts = []\n",
        "for bigram in most_common_fourgrams_abstract:\n",
        "  counts += [bigram[1][0]]\n",
        "\n",
        "plt.barh(range(len(bigrams)), counts, color='skyblue')\n",
        "plt.yticks(range(len(bigrams)), [' '.join(bigram) for bigram in bigrams])\n",
        "plt.xlabel('Occurrence Count')\n",
        "plt.ylabel('Fourgrams')\n",
        "plt.title('Occurrence Count of Fourgrams')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Td_V_JpViKd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Теперь смотрим на самые цитируемые статьи"
      ],
      "metadata": {
        "id": "4RtEInVyIuEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "most_common_bigrams_abstract = get_most_common_phrases_in_column_best(n=2, num_phrases=20)\n",
        "\n",
        "bigrams = [bigram[0] for bigram in most_common_bigrams_abstract]\n",
        "counts = []\n",
        "for bigram in most_common_bigrams_abstract:\n",
        "  counts += [bigram[1][0]]\n",
        "\n",
        "plt.barh(range(len(bigrams)), counts, color='skyblue')\n",
        "plt.yticks(range(len(bigrams)), [' '.join(bigram) for bigram in bigrams])\n",
        "plt.xlabel('Occurrence Count')\n",
        "plt.ylabel('Bigrams')\n",
        "plt.title('Top papers Occurrence Count of Bigrams')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SLJDq4fDlIC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_common_trigrams_abstract = get_most_common_phrases_in_column_best(n=3, num_phrases=20)\n",
        "\n",
        "bigrams = [bigram[0] for bigram in most_common_trigrams_abstract]\n",
        "counts = []\n",
        "for bigram in most_common_trigrams_abstract:\n",
        "  counts += [bigram[1][0]]\n",
        "\n",
        "plt.barh(range(len(bigrams)), counts, color='skyblue')\n",
        "plt.yticks(range(len(bigrams)), [' '.join(bigram) for bigram in bigrams])\n",
        "plt.xlabel('Occurrence Count')\n",
        "plt.ylabel('Trigrams')\n",
        "plt.title('Top papers Occurrence Count of Trigrams')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L3l-RfNdlI8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_common_trigrams_abstract = get_most_common_phrases_in_column_best(n=4, num_phrases=20)\n",
        "\n",
        "\n",
        "bigrams = [bigram[0] for bigram in most_common_fourgrams_abstract]\n",
        "counts = []\n",
        "for bigram in most_common_fourgrams_abstract:\n",
        "  counts += [bigram[1][0]]\n",
        "\n",
        "plt.barh(range(len(bigrams)), counts, color='skyblue')\n",
        "plt.yticks(range(len(bigrams)), [' '.join(bigram) for bigram in bigrams])\n",
        "plt.xlabel('Occurrence Count')\n",
        "plt.ylabel('Fourgrams')\n",
        "plt.title('Top papers Occurrence Count of Fourgrams')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "febiTYW1JgaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e_35SsYSJijx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}